# Scripts d'enrichissement Untappd

## üîç Probl√®me r√©solu

Le script `parallel_enrichment.py` ne compl√®te pas les donn√©es manquantes car:

1. **Il skip les bi√®res avec `untappd_id`** sans v√©rifier si description/style sont null
2. **Selenium ne fonctionne pas bien en parall√®le** (10 ChromeDriver = crash/conflits)

## üìã Scripts disponibles

### 1. `untappd_enrichment.py` - Enrichissement complet (s√©quentiel)

Pour les **nouvelles bi√®res sans `untappd_id`**:

```bash
cd scripts
python untappd_enrichment.py
```

**Que fait-il?**
- Cherche les bi√®res qui n'ont PAS de `untappd_id`
- Les trouve via l'API Untappd
- Scrape leur page pour description et style
- Ajoute les donn√©es dans la structure

**Temps:** ~2-3h pour 1800 bi√®res (API + scraping)

---

### 2. `complete_untappd_missing_parallel.py` - Compl√©tion parall√®le (RECOMMAND√â pour M1/M2)

**‚≠ê NOUVEAU - Utilise celui-ci pour compl√©ter les donn√©es manquantes rapidement!**

Pour les **bi√®res qui ont d√©j√† `untappd_id` mais `untappd_description: null` ou `untappd_style: null`**:

```bash
cd scripts
python complete_untappd_missing_parallel.py 8  # 8 workers pour M1/M2
```

**Que fait-il?**
- Filtre uniquement les bi√®res avec `untappd_id` mais donn√©es manquantes
- Lance plusieurs ChromeDriver en parall√®le (1 par worker)
- Scrape les pages Untappd pour compl√©ter description et/ou style
- Fusionne les donn√©es dans `descriptions['untappd']` et `styles['untappd']`
- Normalise les URLs (http ‚Üí https)

**Temps:**
- 2900 bi√®res avec 8 workers: ~15-20 min
- 2900 bi√®res avec 4 workers: ~30-35 min

**Recommandations:**
- MacBook M1/M2: 8 workers
- MacBook Intel: 4 workers
- Serveur: 4-6 workers

---

### 2b. `complete_untappd_missing.py` - Compl√©tion s√©quentielle (si probl√®mes avec parall√®le)

Version s√©quentielle (1 seul core):

```bash
cd scripts
python complete_untappd_missing.py
```

**Utilise cette version si:**
- La version parall√®le cause des probl√®mes
- Tu as peu de RAM disponible
- Tu pr√©f√®res une approche plus stable

**Temps:** ~12-20 min pour 373 bi√®res, ~2h pour 2900 bi√®res (~2.5 sec/bi√®re)

**Exemple de sortie:**
```
üîç Recherche des bi√®res √† compl√©ter...
   ‚úì 373 bi√®res √† compl√©ter

üìã Exemples de bi√®res √† compl√©ter:
   1. Disco Soleil - Desc:‚úó Style:‚úó
   2. Moralit√© - Desc:‚úó Style:‚úó
   ...

1/373. üîÑ Disco Soleil
   URL: https://untappd.com/b/_/374544
   üìÑ Description: A session IPA hopped with Citra hops...
   üé® Style: IPA - Session

...

üìä STATISTIQUES FINALES
Bi√®res compl√©t√©es:         373
Descriptions ajout√©es:     373
Styles ajout√©s:            373
Taux de succ√®s:            100.0%
```

---

### 3. `parallel_enrichment.py` - Recherche parall√®le (API seulement)

Pour les **nouvelles bi√®res** en mode rapide (sans scraping):

```bash
cd scripts
python parallel_enrichment.py untappd 10
```

**Que fait-il?**
- Lance 10 workers en parall√®le
- Utilise UNIQUEMENT l'API Untappd (pas de scraping)
- Tr√®s rapide mais donn√©es limit√©es (pas de description/style)

**‚ö†Ô∏è Limitations:**
- Ne compl√®te PAS les donn√©es manquantes
- Skip toutes les bi√®res avec `untappd_id` existant
- Pas de scraping (description et style souvent null)

**Temps:** ~5-10 min pour 1800 bi√®res (API seulement)

---

## üöÄ Workflow recommand√©

### Pour enrichir un nouveau dataset complet:

```bash
# 1. Recherche rapide des IDs Untappd (parall√®le)
python parallel_enrichment.py untappd 10

# 2. Compl√®te les donn√©es manquantes (scraping s√©quentiel)
python complete_untappd_missing.py
```

### Pour compl√©ter des donn√©es existantes avec untappd_id:

```bash
# Compl√®te juste les donn√©es manquantes
python complete_untappd_missing.py
```

---

## üîß Installation pr√©alable

Avant de lancer ces scripts, installe les d√©pendances:

```bash
cd scripts

# Test si Selenium fonctionne
python test_selenium_setup.py

# Si erreur, installe les d√©pendances
pip install -r requirements_scraping.txt
```

Tu devrais voir:
```
‚úÖ Tout est pr√™t pour le scraping!
```

---

## üìä Comparaison des scripts

| Script | Vitesse | Donn√©es compl√®tes | Multiprocessing | Cas d'usage |
|--------|---------|-------------------|-----------------|-------------|
| `parallel_enrichment.py` | ‚ö°‚ö°‚ö° Tr√®s rapide | ‚ùå Non (API only) | ‚úÖ Oui | Nouvelles bi√®res, recherche rapide |
| `untappd_enrichment.py` | ‚ö° Lent | ‚úÖ Oui (API + scraping) | ‚ùå Non | Nouvelles bi√®res, donn√©es compl√®tes |
| `complete_untappd_missing_parallel.py` | ‚ö°‚ö°‚ö° Rapide | ‚úÖ Oui (scraping) | ‚úÖ Oui | **Compl√©ter donn√©es manquantes (RECOMMAND√â)** |
| `complete_untappd_missing.py` | ‚ö°‚ö° Moyen | ‚úÖ Oui (scraping) | ‚ùå Non | Compl√©ter donn√©es (fallback) |

---

## üêõ D√©pannage

### "D√©j√† avec Untappd: 2873, Trouv√©s: 0"

Tu as utilis√© `parallel_enrichment.py` qui skip les bi√®res existantes.

**Solution:** Utilise `complete_untappd_missing.py` √† la place.

### "Selenium non disponible"

**Solution:**
```bash
pip install -r requirements_scraping.txt
python test_selenium_setup.py
```

### Le scraping est trop lent

C'est normal! Scraper = 2-3 sec/page.

Pour 373 bi√®res: ~12-20 minutes.

Le script affiche la progression et temps restant.

---

## üìù Structure des donn√©es apr√®s enrichissement

Avant:
```json
{
  "name": "Disco Soleil",
  "untappd_id": 374544,
  "untappd_url": "https://untappd.com/b/_/374544",
  "untappd_description": null,
  "untappd_style": null
}
```

Apr√®s:
```json
{
  "name": "Disco Soleil",
  "untappd_id": 374544,
  "untappd_url": "https://untappd.com/b/_/374544",
  "untappd_description": "A session IPA hopped with Citra hops...",
  "untappd_style": "IPA - Session",
  "descriptions": {
    "beaudegat": "...",
    "untappd": "A session IPA hopped with Citra hops..."
  },
  "styles": {
    "beaudegat": "HOUBLONN√âE",
    "untappd": "IPA - Session"
  }
}
```

---

## üîç Logique de matching (pour untappd_enrichment.py)

Le script utilise une **logique de match exact** pour √©viter les faux positifs:

### Crit√®res de matching

Pour qu'un r√©sultat Untappd soit consid√©r√© comme un match:

1. **Nom du produit** : Le `beer_name` doit √™tre **EXACTEMENT** identique au `name` de la bi√®re
   - Normalisation: minuscules, sans accents, sans ponctuation
   - Pas de mots suppl√©mentaires accept√©s
   - Le nombre de tokens doit √™tre identique (¬±1 tol√©r√©)

2. **Nom de la brasserie** : Le `brewery_name` doit correspondre au `producer`
   - Ignore les mots courants: "Brasserie", "Microbrasserie", "inc.", etc.
   - Au moins 60% des tokens significatifs doivent matcher

3. **Ratings minimum** : La bi√®re doit avoir au moins 5 ratings sur Untappd
   - √âvite les fiches quasi vides ou peu fiables

### Exemples

‚úÖ **Match accept√©**
```
Bi√®re:   Fardeau (Messorem Bracitorium)
Untappd: Fardeau (Brasserie Messorem Bracitorium)
‚Üí ID: 123456, Rating: 3.85 (250 ratings)
```

‚ùå **Match rejet√© - variante**
```
Bi√®re:   Fardeau (Messorem Bracitorium)
Untappd: Fardeau Xtrm Turbo (Brasserie Messorem Bracitorium)
‚Üí Pas de match (mots suppl√©mentaires dans le nom)
```

‚ùå **Match rejet√© - mauvais producteur**
```
Bi√®re:   Fardeau (Messorem Bracitorium)
Untappd: Fardeau (Different Brewery)
‚Üí Pas de match (producteur ne correspond pas)
```

---

## ‚ö° Performance

### API seulement (pas de scraping)
- **parallel_enrichment.py**: 2 requ√™tes/sec √ó 10 workers = ~20 bi√®res/sec
  - Pour 1800 bi√®res: ~5-10 minutes
  - Pour 2900 bi√®res: ~8-15 minutes

### Scraping complet (avec description et style)
- **complete_untappd_missing_parallel.py** (8 workers M1/M2):
  - Pour 373 bi√®res: ~3-5 minutes
  - Pour 2900 bi√®res: ~15-20 minutes
  - Vitesse: ~2.4 bi√®res/sec

- **complete_untappd_missing_parallel.py** (4 workers):
  - Pour 373 bi√®res: ~6-10 minutes
  - Pour 2900 bi√®res: ~30-35 minutes
  - Vitesse: ~1.2 bi√®res/sec

- **untappd_enrichment.py** (s√©quentiel): ~2.5 sec/bi√®re
  - Pour 1800 bi√®res: ~75-90 minutes
  - Pour 2900 bi√®res: ~2 heures
  - Vitesse: ~0.4 bi√®re/sec

- **complete_untappd_missing.py** (s√©quentiel): ~2.5 sec/bi√®re
  - Pour 373 bi√®res: ~12-20 minutes
  - Pour 2900 bi√®res: ~2 heures
  - Vitesse: ~0.4 bi√®re/sec

### Gain avec parall√©lisation (8 workers vs s√©quentiel)
- **8x plus rapide** pour le scraping Untappd
- 2900 bi√®res: 15-20 min vs 2h = **√©conomie de ~1h40**

---

## üõ°Ô∏è S√©curit√©

- Le script cr√©e automatiquement un backup avant de modifier les donn√©es
- En cas d'erreur ou d'interruption, les donn√©es partielles sont sauvegard√©es
- Aucune donn√©e n'est supprim√©e, seulement des champs sont ajout√©s

---

## üìö API Untappd (Algolia)

L'API utilis√©e est l'API publique de recherche Algolia d'Untappd:

```
POST https://9wbo4rq3ho-dsn.algolia.net/1/indexes/beer/query
```

Headers:
- `x-algolia-agent`: Algolia for vanilla JavaScript 3.24.8
- `x-algolia-application-id`: 9WBO4RQ3HO
- `x-algolia-api-key`: 1d347324d67ec472bb7132c66aead485
- `Content-Type`: application/json

Body:
```json
{
  "query": "Messorem Bracitorium Fardeau",
  "hitsPerPage": 12
}
```
