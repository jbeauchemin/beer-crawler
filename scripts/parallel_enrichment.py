import json
import multiprocessing as mp
from pathlib import Path
from typing import List, Dict
import time


def enrich_chunk(args):
    """
    Enrichit un chunk de bi√®res (appel√© par chaque worker)

    Args:
        args: tuple (beers_chunk, chunk_id, script_type, delay)
    """
    beers_chunk, chunk_id, script_type, delay = args

    # Import le bon enricher
    if script_type == 'upc':
        from upc_enrichment import UPCEnricher
        enricher = UPCEnricher(delay=delay)
    elif script_type == 'untappd':
        from untappd_enrichment import UntappdEnricher
        enricher = UntappdEnricher(delay=delay)
    else:
        raise ValueError(f"Unknown script type: {script_type}")

    print(f"[Worker {chunk_id}] D√©marrage - {len(beers_chunk)} bi√®res √† traiter")

    # Enrichit le chunk
    enriched = []
    for i, beer in enumerate(beers_chunk):
        # Skip si d√©j√† enrichi
        if script_type == 'upc' and beer.get('upc'):
            enricher.stats['already_has_upc'] += 1
            enriched.append(beer)
            continue
        elif script_type == 'untappd' and beer.get('untappd_id'):
            enricher.stats['already_has_untappd'] += 1
            enriched.append(beer)
            continue

        # Affiche la progression tous les 10 items
        if i % 10 == 0 and i > 0:
            print(f"[Worker {chunk_id}] Progression: {i}/{len(beers_chunk)}")

        # Enrichit la bi√®re
        if script_type == 'upc':
            print(f"[Worker {chunk_id}] üîç {beer.get('name')} ({beer.get('producer')})")
            upc = enricher.search_upc(beer)
            if upc:
                beer['upc'] = upc
                enricher.stats['found'] += 1
            else:
                enricher.stats['not_found'] += 1
        else:  # untappd
            print(f"[Worker {chunk_id}] üîç {beer.get('name')} ({beer.get('producer')})")
            data = enricher.search_untappd(beer)
            if data:
                beer.update(data)
                enricher.stats['found'] += 1
            else:
                enricher.stats['not_found'] += 1

        enriched.append(beer)
        time.sleep(delay)

    print(f"[Worker {chunk_id}] ‚úì Termin√© - {enricher.stats['found']} trouv√©s")

    return {
        'chunk_id': chunk_id,
        'beers': enriched,
        'stats': enricher.stats
    }


def parallel_enrich(script_type: str, num_workers: int = 4):
    """
    Lance l'enrichissement en parall√®le

    Args:
        script_type: 'upc' ou 'untappd'
        num_workers: Nombre de workers parall√®les (d√©faut: 4)
    """

    # Chemins des fichiers
    input_file = Path('../data/beers_merged.json')
    if not input_file.exists():
        input_file = Path('../datas/beers_merged.json')

    if not input_file.exists():
        print("‚ùå Erreur: Fichier beers_merged.json introuvable!")
        return

    output_file = input_file
    backup_file = input_file.parent / f"{input_file.stem}_{script_type}_backup.json"

    print("="*60)
    print(f"üöÄ ENRICHISSEMENT {script_type.upper()} EN PARALL√àLE")
    print("="*60)
    print(f"Fichier d'entr√©e:  {input_file}")
    print(f"Fichier de sortie: {output_file}")
    print(f"Workers:           {num_workers}")
    print(f"D√©lai par worker:  0.5s")
    print("="*60)

    # Charge les donn√©es
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            beers = json.load(f)
        print(f"‚úì {len(beers)} bi√®res charg√©es")
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return

    # Cr√©e le backup
    try:
        with open(backup_file, 'w', encoding='utf-8') as f:
            json.dump(beers, f, ensure_ascii=False, indent=2)
        print(f"‚úì Backup cr√©√©: {backup_file}")
    except Exception as e:
        print(f"‚ö† Backup impossible: {e}")

    # Divise en chunks
    chunk_size = len(beers) // num_workers
    chunks = []

    for i in range(num_workers):
        start = i * chunk_size
        end = start + chunk_size if i < num_workers - 1 else len(beers)
        chunk = beers[start:end]
        chunks.append((chunk, i, script_type, 0.5))

    print(f"\nüìä R√©partition:")
    for i, (chunk, _, _, _) in enumerate(chunks):
        print(f"   Worker {i}: {len(chunk)} bi√®res")

    print(f"\nüöÄ D√©marrage des {num_workers} workers...\n")

    # Lance les workers en parall√®le
    start_time = time.time()

    with mp.Pool(processes=num_workers) as pool:
        results = pool.map(enrich_chunk, chunks)

    elapsed = time.time() - start_time

    # Reconstitue les donn√©es
    print(f"\nüì¶ Assemblage des r√©sultats...")

    enriched_beers = []
    total_stats = {
        'found': 0,
        'not_found': 0,
        'already_has_upc': 0 if script_type == 'upc' else 0,
        'already_has_untappd': 0 if script_type == 'untappd' else 0
    }

    for result in sorted(results, key=lambda x: x['chunk_id']):
        enriched_beers.extend(result['beers'])
        total_stats['found'] += result['stats']['found']
        total_stats['not_found'] += result['stats']['not_found']
        if script_type == 'upc':
            total_stats['already_has_upc'] += result['stats'].get('already_has_upc', 0)
        else:
            total_stats['already_has_untappd'] += result['stats'].get('already_has_untappd', 0)

    # Sauvegarde
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(enriched_beers, f, ensure_ascii=False, indent=2)
        print(f"‚úì Sauvegard√©: {output_file}")
    except Exception as e:
        print(f"‚ùå Erreur sauvegarde: {e}")
        return

    # Statistiques
    print("\n" + "="*60)
    print("üìä STATISTIQUES FINALES")
    print("="*60)
    print(f"Total de bi√®res:        {len(beers)}")

    if script_type == 'upc':
        print(f"D√©j√† avec UPC:          {total_stats['already_has_upc']}")
    else:
        print(f"D√©j√† avec Untappd:      {total_stats['already_has_untappd']}")

    print(f"Trouv√©s:                {total_stats['found']}")
    print(f"Non trouv√©s:            {total_stats['not_found']}")
    print(f"\nTemps total:            {elapsed:.1f}s")
    print(f"Vitesse:                {len(beers)/elapsed:.1f} bi√®res/sec")

    to_process = len(beers) - (total_stats.get('already_has_upc', 0) or total_stats.get('already_has_untappd', 0))
    if to_process > 0:
        success_rate = (total_stats['found'] / to_process) * 100
        print(f"Taux de succ√®s:         {success_rate:.1f}%")

    print("="*60)


def main():
    import sys

    if len(sys.argv) < 2:
        print("Usage:")
        print("  python parallel_enrichment.py upc [workers]")
        print("  python parallel_enrichment.py untappd [workers]")
        print()
        print("Exemples:")
        print("  python parallel_enrichment.py upc 4        # 4 workers pour UPC")
        print("  python parallel_enrichment.py untappd 8    # 8 workers pour Untappd")
        print()
        print("Recommandations:")
        print("  M1/M2 MacBook: 4-8 workers")
        print("  Plus de workers = plus rapide, mais attention au rate limiting!")
        sys.exit(1)

    script_type = sys.argv[1].lower()

    if script_type not in ['upc', 'untappd']:
        print(f"‚ùå Type invalide: {script_type}")
        print("   Types valides: upc, untappd")
        sys.exit(1)

    num_workers = int(sys.argv[2]) if len(sys.argv) > 2 else 4

    if num_workers < 1 or num_workers > 16:
        print(f"‚ùå Nombre de workers invalide: {num_workers}")
        print("   Recommand√©: 4-8 workers")
        sys.exit(1)

    print(f"\n‚ö° Mode parall√®le: {num_workers} workers\n")

    parallel_enrich(script_type, num_workers)


if __name__ == "__main__":
    main()
