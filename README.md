# ğŸº Beer Crawler - RÃ©cupÃ©ration de donnÃ©es de biÃ¨res

Collection de crawlers pour extraire les informations de biÃ¨res depuis diffÃ©rents sites de microbrasseries quÃ©bÃ©coises.

## ğŸ“‹ Table des matiÃ¨res

- [Crawlers spÃ©cifiques](#crawlers-spÃ©cifiques)
- [Crawler Universel](#-crawler-universel-nouveau)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Scripts utilitaires](#scripts-utilitaires)

---

## Crawlers spÃ©cifiques

### Sites supportÃ©s

| Site | Fichier | Description |
|------|---------|-------------|
| [Beau de Gat](https://beaudegat.ca) | `beaudegat.py` | Crawl des biÃ¨res avec style, alcool, volume |
| [Espace Houblon](https://espacehoublon.ca) | `espace-houblon.py` | WooCommerce, filtre produits biÃ¨re |
| [La BiÃ¨re Ã  Boire](https://labiereaboire.com) | `labiereaboire.py` | Pagination robuste, UPC |
| [Veux-tu une biÃ¨re](https://veuxtuunebiere.com) | `vtub.py` | BiÃ¨res alcoolisÃ©es + sans alcool |
| [Ma Soif](https://masoif.com) | `masoif.py` | DonnÃ©es complÃ¨tes (IBU, rÃ©gion) |

### CaractÃ©ristiques communes

âœ… Sauvegarde progressive (pas de perte de donnÃ©es)
âœ… Gestion de la pagination
âœ… Extraction de photos haute rÃ©solution
âœ… Export en JSON
âœ… Gestion des erreurs robuste

---

## ğŸš€ Crawler Universel (NOUVEAU!)

Le **Universal Beer Crawler** peut crawler **n'importe quel site de microbrasserie** automatiquement, sans configuration !

### âœ¨ FonctionnalitÃ©s

- ğŸ” **DÃ©tection automatique** de la structure du site
- ğŸ§  **Adaptation intelligente** Ã  diffÃ©rentes plateformes (Shopify, WooCommerce, WordPress, Custom)
- ğŸ“„ **DÃ©couverte automatique** des pages de produits et pagination
- ğŸ¯ **Extraction intelligente** des donnÃ©es (nom, prix, alcool, volume, IBU, style, etc.)
- ğŸ’¾ **Sauvegarde progressive** aprÃ¨s chaque produit
- ğŸ”§ **Configuration auto-apprise** sauvegardÃ©e pour rÃ©utilisation

### ğŸ¬ Utilisation

```bash
# Crawler n'importe quel site de brasserie
python crawler/universal-crawler.py https://dieuduciel.com

# SpÃ©cifier le fichier de sortie
python crawler/universal-crawler.py https://autre-brasserie.com beers_custom.json
```

### ğŸ“Š Ce qui est extrait automatiquement

| DonnÃ©e | MÃ©thodes de dÃ©tection |
|--------|----------------------|
| **Nom** | `<h1>`, `og:title`, `<title>` |
| **Prix** | Classes "price", `itemprop="price"`, `data-price` |
| **Description** | Classes "description", `itemprop="description"` |
| **Photo** | `og:image`, images de galerie produit |
| **Alcool (%)** | Regex `\d+%` avec validation (0-20%) |
| **Volume (ml)** | Regex `\d+ ml` avec validation (100-5000ml) |
| **IBU** | Regex `\d+ IBU` avec validation (0-150) |
| **Producteur** | Liens catÃ©gories, meta brand |
| **Style** | Liens catÃ©gories de style/type |

### ğŸ¯ Exemple de sortie

```json
{
  "url": "https://example.com/products/ipa-americaine",
  "name": "IPA AmÃ©ricaine HoublonnÃ©e",
  "price": "4,25$",
  "producer": "Dieu du Ciel",
  "style": "IPA",
  "sub_style": "American IPA",
  "volume": "473ml",
  "alcohol": "6.5%",
  "ibu": "65",
  "description": "Une IPA bien houblonnÃ©e avec des notes d'agrumes...",
  "photo_url": "https://example.com/images/ipa.jpg"
}
```

### âš™ï¸ Comment Ã§a fonctionne

1. **DÃ©couverte** : Analyse la homepage et trouve les pages de produits
2. **Exploration** : Parcourt les pages de listing et gÃ¨re la pagination automatiquement
3. **Extraction** : Pour chaque produit, extrait intelligemment toutes les donnÃ©es
4. **Validation** : Valide les donnÃ©es extraites (prix, alcool, volume dans des plages raisonnables)
5. **Sauvegarde** : Enregistre progressivement en JSON

### ğŸ“ Fichiers gÃ©nÃ©rÃ©s

- `beers_universal.json` : DonnÃ©es des biÃ¨res extraites
- `product_links_discovered.txt` : Liste de tous les liens de produits trouvÃ©s
- `crawler_config.json` : Configuration dÃ©couverte (plateforme, patterns, sÃ©lecteurs)

---

## Installation

### PrÃ©requis

- Python 3.8+
- Google Chrome ou Chromium
- ChromeDriver

### DÃ©pendances Python

```bash
# CrÃ©er un environnement virtuel (recommandÃ©)
python3 -m venv env
source env/bin/activate

# Installer les dÃ©pendances
pip install selenium beautifulsoup4 requests
```

### Configuration Chrome

Les crawlers utilisent Chrome en mode headless. Assurez-vous que Chrome et ChromeDriver sont installÃ©s :

```bash
# Ubuntu/Debian
sudo apt-get install chromium-browser chromium-chromedriver

# macOS (avec Homebrew)
brew install --cask google-chrome
brew install chromedriver
```

---

## Utilisation

### Crawlers spÃ©cifiques

```bash
# Activer l'environnement virtuel
source env/bin/activate

# Exemple : Crawler Beau de Gat
python crawler/beaudegat.py

# Exemple : Crawler Espace Houblon
python crawler/espace-houblon.py
```

### Crawler Universel

```bash
# Crawler n'importe quel site
python crawler/universal-crawler.py https://dieuduciel.com

# Avec fichier de sortie personnalisÃ©
python crawler/universal-crawler.py https://brasserie.com output.json
```

### Analyser un nouveau site

Avant de crawler, vous pouvez analyser la structure du site :

```bash
# Analyse la structure et gÃ©nÃ¨re un rapport
python crawler/site-analyzer-lite.py https://nouveau-site.com
```

Cela gÃ©nÃ¨re `site_analysis.json` avec :
- Plateforme dÃ©tectÃ©e
- Pages de listing trouvÃ©es
- Exemples de produits analysÃ©s
- SÃ©lecteurs CSS identifiÃ©s

---

## Scripts utilitaires

### ğŸ”€ Fusion de donnÃ©es (`beer-merge.py`)

Fusionne les donnÃ©es de plusieurs sources en dÃ©tectant les doublons :

```python
from beer_merger import BeerMerger

merger = BeerMerger(producer_threshold=0.6, name_threshold=0.8)
merged_beers = merger.merge_beers([
    'beers_beaudegat.json',
    'beers_espacehoublon.json',
    'beers_lbab.json',
    'beers_masoif.json',
    'beers_vtub.json'
])
merger.save_merged_beers(merged_beers, 'beers_merged.json')
```

**FonctionnalitÃ©s** :
- DÃ©tection intelligente des doublons (matching flou)
- Gestion des variantes (lime, citron, etc.)
- SÃ©paration packs vs singles
- Conservation de toutes les sources

### ğŸ” Recherche de biÃ¨res (`beer-finder.py`)

Recherche dans les donnÃ©es crawlÃ©es :

```python
from beer_finder import BeerFinder

finder = BeerFinder(['beers_merged.json'])
results = finder.search(producer="Dieu du Ciel", name="IPA")
finder.display_results(results)
```

### ğŸ–¼ï¸ Traitement d'images (`process_images.py`)

Supprime l'arriÃ¨re-plan et exporte en WebP :

```bash
python scripts/process_images.py \
  --in images \
  --out out \
  --canvas 900 \
  --pad 40 \
  --shadow \
  --outline 2 \
  --bg transparent
```

---

## Structure du projet

```
beer-crawler/
â”œâ”€â”€ crawler/
â”‚   â”œâ”€â”€ beaudegat.py              # Crawler Beau de Gat
â”‚   â”œâ”€â”€ espace-houblon.py         # Crawler Espace Houblon
â”‚   â”œâ”€â”€ labiereaboire.py          # Crawler La BiÃ¨re Ã  Boire
â”‚   â”œâ”€â”€ vtub.py                   # Crawler Veux-tu une biÃ¨re
â”‚   â”œâ”€â”€ masoif.py                 # Crawler Ma Soif
â”‚   â”œâ”€â”€ universal-crawler.py      # ğŸš€ Crawler Universel
â”‚   â”œâ”€â”€ site-analyzer-lite.py     # Analyseur de site (sans Selenium)
â”‚   â””â”€â”€ beer-merge.py             # Fusion de donnÃ©es
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ beer-finder.py            # Recherche de biÃ¨res
â”‚   â””â”€â”€ process_images.py         # Traitement d'images
â”œâ”€â”€ README.md                     # Ce fichier
â””â”€â”€ .gitignore
```

---

## Format de donnÃ©es

Toutes les biÃ¨res sont sauvegardÃ©es en JSON avec la structure suivante :

```json
{
  "url": "URL du produit",
  "name": "Nom de la biÃ¨re",
  "price": "Prix (ex: 4,25$)",
  "producer": "Nom du producteur/brasserie",
  "style": "Style principal (ex: IPA)",
  "sub_style": "Sous-style (ex: American IPA)",
  "volume": "Volume (ex: 473ml)",
  "alcohol": "Taux d'alcool (ex: 6.5%)",
  "ibu": "IBU (optionnel)",
  "region": "RÃ©gion (optionnel)",
  "description": "Description de la biÃ¨re",
  "photo_url": "URL de la photo",
  "availability": "DisponibilitÃ© (optionnel)"
}
```

---

## ğŸ¯ Cas d'usage

### 1. Crawler un nouveau site rapidement

```bash
python crawler/universal-crawler.py https://nouvelle-brasserie.com
```

### 2. Analyser avant de crawler

```bash
# 1. Analyse d'abord
python crawler/site-analyzer-lite.py https://site.com

# 2. VÃ©rifie site_analysis.json

# 3. Crawl avec le crawler universel
python crawler/universal-crawler.py https://site.com
```

### 3. Fusionner plusieurs sources

```bash
# Crawler plusieurs sites
python crawler/universal-crawler.py https://site1.com beers_site1.json
python crawler/universal-crawler.py https://site2.com beers_site2.json

# Fusionner
python crawler/beer-merge.py  # (ajuster les chemins dans le script)
```

---

## Conseils et bonnes pratiques

### ğŸ• Respect des sites

- **Delay** : Les crawlers incluent des pauses (1-2s) entre les requÃªtes
- **Headers** : User-Agent rÃ©aliste pour Ã©viter les blocages
- **Rate limiting** : Ne pas surcharger les serveurs

### ğŸ› Debugging

Si le crawler ne trouve pas de donnÃ©es :

1. VÃ©rifier que le site est accessible
2. Analyser avec `site-analyzer-lite.py`
3. VÃ©rifier les logs pour identifier les problÃ¨mes
4. Ajuster les sÃ©lecteurs si nÃ©cessaire (mode non-headless pour voir le navigateur)

### ğŸ’¾ Sauvegarde progressive

Tous les crawlers sauvegardent aprÃ¨s chaque produit :
- Pas de perte de donnÃ©es en cas d'interruption
- PossibilitÃ© de reprendre oÃ¹ on s'est arrÃªtÃ©

---

## ğŸ¤ Contribution

Pour ajouter un nouveau site spÃ©cifique :

1. CrÃ©er un nouveau fichier `crawler/nouveau-site.py`
2. S'inspirer de la structure des crawlers existants
3. Tester avec le crawler universel d'abord !

---

## ğŸ“œ Licence

Usage personnel et Ã©ducatif. Respectez les conditions d'utilisation des sites crawlÃ©s.

---

## ğŸ†˜ Support

Pour des questions ou problÃ¨mes :
1. VÃ©rifier que toutes les dÃ©pendances sont installÃ©es
2. Tester avec le crawler universel
3. Consulter les logs d'erreur
4. VÃ©rifier que Chrome/ChromeDriver fonctionne

---

**Fait avec ğŸº pour les amateurs de biÃ¨res artisanales quÃ©bÃ©coises !**
